{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e8283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0dc36b",
   "metadata": {},
   "source": [
    "Reading the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b73662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r\"C:\\Users\\himan\\AppData\\Local\\Packages\\Microsoft.Office.OneNote_8wekyb3d8bbwe\\AppData\\Local\\Jyotsana\\Programming\\MIT\\Student\\student-mat.csv\",delimiter=\";\")\n",
    "df2 = pd.read_csv(r\"C:\\Users\\himan\\AppData\\Local\\Packages\\Microsoft.Office.OneNote_8wekyb3d8bbwe\\AppData\\Local\\Jyotsana\\Programming\\MIT\\Student\\student-por.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dac0d99",
   "metadata": {},
   "source": [
    "handling grade columns for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6918b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.rename(columns={\"G1\": \"MG1\", \"G2\": \"MG2\", \"G3\": \"MG3\"})\n",
    "df2 = df2.rename(columns={\"G1\": \"PG1\", \"G2\": \"PG2\", \"G3\": \"PG3\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6fa311",
   "metadata": {},
   "source": [
    "adding necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccff2c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"subject\"] = \"math\"\n",
    "df2[\"subject\"] = \"portuguese\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec9a4fb",
   "metadata": {},
   "source": [
    "finding and removing null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df1.isnull().sum()\n",
    "b = df2.isnull().sum()\n",
    "clean_df1 = df1.dropna()\n",
    "clean_df2 = df2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e76d5c",
   "metadata": {},
   "source": [
    "checking shape of data and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_shape = clean_df1.shape\n",
    "df1_type = clean_df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2909b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_shape = clean_df2.shape\n",
    "df2_type = clean_df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe2f33",
   "metadata": {},
   "source": [
    "merging the data to get the clean information of both data sets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db38b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.concat([clean_df1, clean_df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab78530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting index points of similar data\n",
    "a = merged_data.columns.get_loc('school')\n",
    "b = merged_data.columns.get_loc('absences') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49f0fdf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#set of columns which are simillar\n",
    "set = merged_data.columns[a:b].tolist()\n",
    "modified_data = merged_data.drop_duplicates(subset=set, keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52309099",
   "metadata": {},
   "source": [
    "CALCULATIONS:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f490696",
   "metadata": {},
   "source": [
    "Average Final Grade-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maths\n",
    "avg_m = clean_df1[\"MG3\"].mean()\n",
    "print(\"Average Final Grade for Maths:\", avg_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73918857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#porteguese\n",
    "avg_p = clean_df2[\"PG3\"].mean()\n",
    "print(\"Average Final Grade for Portuguese:\", avg_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639f8b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#both subjects together\n",
    "avg_b = pd.concat([clean_df1[\"MG3\"], clean_df2[\"PG3\"]]).mean()\n",
    "print(\"Average Final Grade for Both Subjects:\", avg_b)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2d2fb0",
   "metadata": {},
   "source": [
    "Number of Students who scored above 15-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95bd28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Students who scored above 15 in Maths:\", (clean_df1[\"MG3\"]>15).sum())\n",
    "print(\"Number of Students who scored above 15 in Portuguese:\", (clean_df2[\"PG3\"]>15).sum())\n",
    "print(\"Number of Students who scored above 15 in Both Subjects:\", (pd.concat([clean_df1[\"MG3\"], clean_df2[\"PG3\"]])>15).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338366fb",
   "metadata": {},
   "source": [
    "My clean_df1[\"MG3\"]>15 checks the value of MG3 if its greater than 15 it gives true else false and as we know 1 is for true and 0 for false. So, when we sum it we get the sum of these 1 and 0's i.e, count of the students who scored above 15 points. \n",
    "This same goes for porteguese and for both subjects together also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f863571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264e7d9f",
   "metadata": {},
   "source": [
    "Studytime correlation with Performance-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bab9803",
   "metadata": {},
   "source": [
    "We can see it by using corr function in study time (provided) and performace (scores of G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1111be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maths\n",
    "corr_m = clean_df1[\"studytime\"].corr(clean_df1[\"MG3\"])\n",
    "print(\"Correlation between Study Time and Performance in Maths:\", corr_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756356c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#portuguese\n",
    "corr_p = clean_df2[\"studytime\"].corr(clean_df2[\"PG3\"])\n",
    "print(\"Correlation between Study Time and Performance in Portuguese:\", corr_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f129b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#both subjects\n",
    "corr_b = pd.concat([clean_df1[\"studytime\"], clean_df2[\"studytime\"]]).corr(pd.concat([clean_df1[\"MG3\"], clean_df2[\"PG3\"]]))\n",
    "print(\"Correlation between Study Time and Performance in Both Subjects:\", corr_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309cac33",
   "metadata": {},
   "source": [
    "(positive correlation means as study time increases performance also increases and as negative correlation means as study time increases performance decreases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aaa3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60629ab",
   "metadata": {},
   "source": [
    "Average Gender Performance-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cd37bb",
   "metadata": {},
   "source": [
    "We can find it by using G3 score and grouping it on basis of gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a612e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maths\n",
    "gen_perf_m = clean_df1.groupby(\"sex\")[\"MG3\"].mean()\n",
    "print(\"Average Gender Performance in Maths:\", gen_perf_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933e1c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#portuguese\n",
    "gen_perf_p = clean_df2.groupby(\"sex\")[\"PG3\"].mean()\n",
    "print(\"Average Gender Performance in Portuguese:\", gen_perf_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423dc81c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#both subjects\n",
    "gen_perf_b = pd.concat([clean_df1.groupby(\"sex\")[\"MG3\"].mean(), clean_df2.groupby(\"sex\")[\"PG3\"].mean()], axis=1)\n",
    "gen_perf_b.columns = [\"Maths\", \"Portuguese\"]\n",
    "print(\"Average Gender Performance in Both Subjects:\", gen_perf_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1531be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cca581",
   "metadata": {},
   "source": [
    "VISUALIZATION:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98145f1d",
   "metadata": {},
   "source": [
    "Histogram for Final Grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3374acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maths\n",
    "plt.hist(clean_df1[\"MG3\"], bins=20, alpha=0.7, label=\"Maths\", color='blue')\n",
    "plt.xlabel(\"Final Grade\")\n",
    "plt.ylabel(\"Number of Students\")\n",
    "plt.title(\"Histogram of Final Grades\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c728a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#portuguese\n",
    "plt.hist(clean_df2[\"PG3\"], bins=20, alpha=0.7, label=\"Portuguese\", color='green')\n",
    "plt.xlabel(\"Final Grade\")\n",
    "plt.ylabel(\"Number of Students\")\n",
    "plt.title(\"Histogram of Final Grades\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38b3af",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#for both subjects\n",
    "plt.hist(pd.concat([clean_df1[\"MG3\"], clean_df2[\"PG3\"]]), bins=20, alpha=0.7, label=\"Both Subjects\", color='orange')\n",
    "plt.xlabel(\"Final Grade\")\n",
    "plt.ylabel(\"Number of Students\")\n",
    "plt.title(\"Histogram of Final Grades\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75616aab",
   "metadata": {},
   "source": [
    "Scatterplot for Correlation of StudyTime and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e39fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maths\n",
    "plt.scatter(clean_df1[\"studytime\"], clean_df1[\"MG3\"])\n",
    "plt.xlabel(\"Study Time\")\n",
    "plt.ylabel(\"Final Grade\")\n",
    "plt.title(\"Study Time vs Performance of Maths\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#portuguese\n",
    "plt.scatter(clean_df2[\"studytime\"], clean_df2[\"PG3\"], color='green', alpha=0.5)\n",
    "plt.xlabel(\"Study Time\")\n",
    "plt.ylabel(\"Final Grade\")\n",
    "plt.title(\"Study Time vs Performance of Portuguese\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc90b9c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#both\n",
    "plt.scatter(pd.concat([clean_df1[\"studytime\"], clean_df2[\"studytime\"]]), pd.concat([clean_df1[\"MG3\"], clean_df2[\"PG3\"]]), color='orange', alpha=0.5)\n",
    "plt.xlabel(\"Study Time\")\n",
    "plt.ylabel(\"Final Grade\")\n",
    "plt.title(\"Study Time vs Performance of Both Subjects\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56507f",
   "metadata": {},
   "source": [
    "Bar chart for Average Gender Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c555c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maths\n",
    "bar_m = clean_df1.groupby(\"sex\")[\"MG3\"].mean()\n",
    "bar_m.plot(kind='bar', color=['blue', 'pink'])\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.ylabel(\"Average Final Grade\")\n",
    "plt.title(\"Average Gender Performance in Maths\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab35cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#portuguese\n",
    "bar_p = clean_df2.groupby(\"sex\")[\"PG3\"].mean()\n",
    "bar_p.plot(kind='bar', color=['blue', 'pink'])\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.ylabel(\"Average Final Grade\")\n",
    "plt.title(\"Average Gender Performance in Portuguese\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd6543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#both subjects\n",
    "bar_b = pd.concat([clean_df1.groupby(\"sex\")[\"MG3\"].mean(), clean_df2.groupby(\"sex\")[\"PG3\"].mean()], axis=1)\n",
    "bar_b.columns = [\"Maths\", \"Portuguese\"]\n",
    "bar_b.plot(kind='bar', color=['orange', 'yellow'])\n",
    "plt.xlabel(\"Gender\")\n",
    "plt.ylabel(\"Average Final Grade\")\n",
    "plt.title(\"Average Gender Performance in Both Subjects\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
